read config from config.txt
Loaded config file successfully.
is_test 0
is_train 1
device-x cpu
device cuda:3
dict_dir ./
word_freq_cutoff 1
model_dir ./
ext_word_emb_full_path /data1/yli/paser/domain-dependency-parsers/data/giga.bin
ext_word_dict_full_path /data1/yli/paser/domain-dependency-parsers/data/extwords.txt
inst_num_max -1
max_bucket_num 80
sent_num_one_batch 200
word_num_one_batch 5000
is_shared_lstm 1
is_meta 1
is_diff_loss 1
is_meta_weight 1
is_adversary 0
is_multi 0
is_charlstm 1
model_eval_num 0
data_dir /data1/yli/paser/domain-dependency-parsers/data/PC
train_files /data1/yli/paser/domain-dependency-parsers/data/BC/train-bc.conll:/data1/yli/paser/domain-dependency-parsers/data/PC/train-comment.conll
dev_files /data1/yli/paser/domain-dependency-parsers/data/PC/dev-comment.conll
test_files /data1/yli/paser/domain-dependency-parsers/data/PC/test-comment.conll
unlabel_train_files /data1/yli/paser/domain-dependency-parsers/data/Unlabeled-pos/comment-unlabel-pos.conll
is_dictionary_exist 0
train_max_eval_num 1000
save_model_after_eval_num 1
train_stop_after_eval_num_no_improve 100
eval_every_update_step_num 184
lstm_layer_num 3
word_emb_dim 100
tag_emb_dim 100
domain_emb_dim 12
domain_size 2
emb_dropout_ratio 0.33
lstm_hidden_dim 400
lstm_input_dropout_ratio 0.33
lstm_hidden_dropout_ratio_for_next_timestamp 0.33
mlp_output_dim_arc 500
mlp_output_dim_rel 100
mlp_input_dropout_ratio 0.33
mlp_output_dropout_ratio 0.33
learning_rate 5e-4
meta_learning_rate 1e-4
meta_loss 0.5
decay .75
decay_steps 5000
beta_1 .7
beta_2 .95
epsilon 1e-12
clip 5.0
adversary_lambda_loss 1
diff_bate_loss 0.01
random_seeds =  [1594965602, 364915762, 198389420, 974236670]
self._file_name_short parsers_data_BC_train-bc.conll
self._domain_id 1
Reading parsers_data_BC_train-bc.conll done: 16339 instances
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  0 1435 10 8 0
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  1 1886 12 10 8
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  2 2007 14 11 18
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  3 1054 15 6 29
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  4 1008 16 6 35
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  5 1017 17 6 41
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  6 1082 18 6 47
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  7 1050 19 6 53
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  8 1032 20 6 59
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  9 1003 21 6 65
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  10 762 22 4 71
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  11 779 23 4 75
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  12 719 24 4 79
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  13 677 25 4 83
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  14 828 31 5 87
parsers_data_BC_train-bc.conll can provide 92 batches in total with 15 buckets
self._file_name_short rs_data_PC_train-comment.conll
self._domain_id 2
Reading rs_data_PC_train-comment.conll done: 6885 instances
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  0 1092 12 6 0
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  1 995 14 5 6
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  2 680 15 4 11
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  3 881 16 5 15
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  4 723 17 4 20
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  5 755 18 4 24
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  6 731 19 4 28
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  7 502 20 3 32
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  8 526 25 3 35
rs_data_PC_train-comment.conll can provide 38 batches in total with 9 buckets
self._file_name_short -pos_comment-unlabel-pos.conll
self._domain_id 2
Reading -pos_comment-unlabel-pos.conll done: 11210 instances
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  0 2159 8 11 0
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  1 1242 10 7 11
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  2 1250 13 7 18
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  3 986 16 5 25
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  4 618 18 4 30
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  5 683 20 4 34
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  6 662 22 4 38
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  7 590 24 3 42
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  8 551 26 3 45
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  9 487 28 3 48
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  10 410 30 3 51
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  11 498 33 3 54
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  12 377 36 3 57
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  13 290 39 2 60
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  14 263 44 2 62
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  15 144 53 2 64
-pos_comment-unlabel-pos.conll can provide 66 batches in total with 16 buckets
create dict...
max_char: 32
max_char: 9
	Saved 34075 vocab into ./dict/words

	Saved 4221 vocab into ./dict/chars

	Saved 32 vocab into ./dict/postags

	Saved 21 vocab into ./dict/labels

create dict done
